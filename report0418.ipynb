{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1aYvPWuKj81gU-hTSLxy2Y3LvR7nofCUt",
      "authorship_tag": "ABX9TyM7j1LXuX1vfCkFfvtn0W2t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/f8sle/report/blob/main/report0418.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 1. 데이터 로딩\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Social_Network_Ads.csv')\n",
        "\n",
        "# 2. 데이터 전처리, 특성 추출\n",
        "X = data[['Age', 'EstimatedSalary']].to_numpy()\n",
        "y = data['Purchased'].to_numpy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 3. 학습 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. 로지스틱 회귀 모델 구성\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def h(x1, x2, w0, w1, w2):\n",
        "    z = w0 + w1 * x1 + w2 * x2\n",
        "    return sigmoid(z)\n",
        "\n",
        "def log_likelihood_single(X_b, y, w):\n",
        "    h = sigmoid(np.dot(X_b, w))\n",
        "    epsilon = 1e-15\n",
        "    h = np.clip(h, epsilon, 1 - epsilon)\n",
        "    loss = -np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
        "    return loss\n",
        "\n",
        "#5 경사하강법\n",
        "def gradient_descent(X, y, learning_rate=0.01, n_iterations=1000):\n",
        "    m, n = X.shape\n",
        "    X_b = np.c_[np.ones((m, 1)), X]\n",
        "    w = np.zeros(n + 1)\n",
        "    loss_history = []\n",
        "\n",
        "    for iteration in range(n_iterations):\n",
        "        h = sigmoid(np.dot(X_b, w))\n",
        "        gradient = (1/m) * np.dot(X_b.T, (h - y))\n",
        "        w -= learning_rate * gradient\n",
        "\n",
        "\n",
        "\n",
        "        loss = log_likelihood_single(X_b, y, w)\n",
        "        loss_history.append(loss)\n",
        "\n",
        "        if iteration % 100 == 0:\n",
        "            print(f\"반복 {iteration}, 손실: {loss:.6f}\")\n",
        "\n",
        "    return w, loss_history\n",
        "\n",
        "\n",
        "\n",
        "#6 시각화\n",
        "def plot_decision_boundary(X, y, w, title):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "\n",
        "    x1_min, x1_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
        "    x2_min, x2_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
        "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, 0.01), np.arange(x2_min, x2_max, 0.01))\n",
        "    X_grid = np.c_[np.ones((xx1.ravel().shape[0], 1)), xx1.ravel(), xx2.ravel()]\n",
        "\n",
        "    Z = sigmoid(np.dot(X_grid, w))\n",
        "    Z = (Z > 0.5).astype(int).reshape(xx1.shape)\n",
        "\n",
        "\n",
        "    plt.contour(xx1, xx2, Z, levels=[0.5], colors='red')\n",
        "\n",
        "\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y,  edgecolors='k', cmap='coolwarm', s=30)\n",
        "\n",
        "    plt.xlabel('Age')\n",
        "    plt.ylabel('Estimated_Salary')\n",
        "    plt.title(title)\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    w, history  = gradient_descent(X_train, y_train, learning_rate=0.1, n_iterations=1000)\n",
        "    print(\"\\nfinal param:\")\n",
        "    print(f\"gradient param: w0={w[0].item():.4f}, w1={w[1].item():.4f}, w2={w[2].item():.4f}\")\n",
        "\n",
        "\n",
        "    plot_decision_boundary(X_train, y_train, w, 'Logistic_Regression')\n",
        "#7 scikit-learn\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nscikit-learn param:\")\n",
        "print(f\"w0={clf.intercept_[0]:.4f}\")\n",
        "print(f\"w1={clf.coef_[0][0]:.4f}, w2={clf.coef_[0][1]:.4f}\")\n",
        "\n",
        "#8 시각화\n",
        "w_sklearn = np.hstack([clf.intercept_, clf.coef_.flatten()])\n",
        "plot_decision_boundary(X_train, y_train, w_sklearn, 'Logistic_Regression (scikit-learn)')\n"
      ],
      "metadata": {
        "id": "_7gk2LDb6FcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FzY9EZlS8ReY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}